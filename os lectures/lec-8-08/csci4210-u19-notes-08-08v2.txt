[08/08/2019]

Exam 2 grade requests due by the end of the week.

Final Exam review packet is released.

Please remember to fill out your course evals! If we get to 85% by Sunday night
we'll release a more complete set of solutions for the review packet.

Final Exam will be a 2 hour test during Thursday 8/15 lecture. You can attend
either section.
If you have accomodations that are the same as during Exam 2, you do not need 
to e-mail me, just assume the same arrangement.
====================

MEMORY MANAGEMENT

Memory Manager:

-- allocate/deallocate memory for processes
	(the OS assigns memory to new/running processes and deallocates memory)

-- protection, i.e., no access to a given process's memory space
		from outside the given process

-- shared memory management (between two or more processes, which could
		include shared libraries, shared memory segments created via shmget(), etc.)

Approaches:
-- Contiguous Memory Allocation
-- Noncontiguous Memory Allocation
-- Virtual Memory

With mulitprogramming, multiple options for managing memory

-- early approaches identified PARTITIONS, where a partition is a block
		of CONTIGUOUS MEMORY that can be allocated to a process

Degree of multiprogramming
-- how many processes can be in memory at once?
-- depends on process size, partition size, amount of memory available
		overall (maybe even process runtime?)

A LOGICAL ADDRESS references some location within a given process address space
	-- think of the logical address an offset from the first byte of the process
		memory (byte 0)

				LOAD x
LABEL:	...
				...
				...
				DECR x
				BNE LABEL			; branch up/backwards 48 bytes

	-- RELOCATABLE CODE

	-- When a process is placed into physical memory,
		its logical address space is bound to a physical memory space

The OS must map every LOGICAL ADDRESS to a PHYSICAL ADDRESS
-- logical addresses are generated by compilers/assemblers

CONTIGUOUS MEMORY ALLOCATION
-- fit the entire process address space into physical memory
	in one contiguous block (no gaps)

	-- this block has a BASE address (e.g., 14000) or starting point
		in physical memory, as well as a LIMIT (size in bytes)

-- Partitioned memory may be FIXED or DYNAMIC

Fixed Partitioning Scheme
-- Given N partitions of potentially different sizes
-- Each process is allocated to exactly one partition
-- Each partition is associated with one process or is marked FREE
-- OS manages a list of free partitions and 
		a mapping of used partitions to processes

MEMORY (fixed partitioning scheme):
-----------------------------------
 DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDD    Partition 1  (64 memory units)
 DDDDDDDDDDDDDDDDDDDDDDDDDD.......
-----------------------------------
 BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB    Partition 2  (64 memory units)
 BBBBBBBBBBB......................
-----------------------------------
 CCCCCCC..........................    Partition 3  (256 memory units)
 .................................
 .................................
 .................................
 .................................
 .................................
 .................................
 .................................
-----------------------------------

-- if process E arrives and requires 8 memory units, we cannot allocate
	a partition for this process because all partitions are in use
	(even though we have enough free memory to support 8 more units being used)

Dynamic Paritioning Scheme
-- the size of a given process will define the size of the allocated parition
-- this is essentially on-demand partitioning

MEMORY (dynamic partitioning scheme):
-----------------------------------
 DDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDDD  
 DDDDDDDDDDDDDDDDDDDDDDDDDDBBBBBBB
 BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB
 BBBBCCCCCCC......................
 .................................   
 .................................
 .................................
 .................................
 .................................
 .................................
 .................................
 .................................
-----------------------------------


MEMORY (dynamic partitioning scheme):
-----------------------------------
 AAAAAAAAAAAAAAAAAAAAAAAAAAAAAABBB   The set of A's defines one partition
 BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB    (for process A), the set of B's defines
 BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB     another partition, etc.
 BCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC
 CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC.
 ....MMMMMMMMMMMMMMMMMMMMMMMMMMMMM
 MMMMMMMMMMMMMMMMMM...............
 .................................   As time goes by, processes arriving
 .................FFFFFFFFFFFFFFFF    and leaving the system cause the memory
 FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF     to become increasingly fragmented
 FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF
 FGGGGGGGGGGGGGGGGGGGG............
 ................HHHHHHHHHH.......
-----------------------------------

If process X arrives and requires more memoRy than the largest free
	partition, we look to defragmentation:

MEMORY (after defragmentation/memory compaction):
-----------------------------------
 AAAAAAAAAAAAAAAAAAAAAAAAAAAAAABBB   
 BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB   
 BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB   
 BCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC
 CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCM
 MMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMM
 MMMMMMMMMMMMMFFFFFFFFFFFFFFFFFFFF
 FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF   
 FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFGGG
 GGGGGGGGGGGGGGGGGHHHHHHHHHH......
 .................................
 .................................   
 .................................   
-----------------------------------

Now X might fit - might still require more free space than we had total.

MEMORY (after defragmentation/memory compaction):
-----------------------------------
 AAAAAAAAAAAAAAAAAAAAAAAAAAAAAABBB   
 BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB   
 BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB   
 BCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC
 CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCM
 MMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMM
 MMMMMMMMMMMMMFFFFFFFFFFFFFFFFFFFF
 FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF   
 FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFGGG
 GGGGGGGGGGGGGGGGGHHHHHHHHHHXXXXXX
 XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
 XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX   
 XXXXXXXXXXXXXXXXXXXXX............   
-----------------------------------

We need an algorithm to determine where to place each newly arriving process
-- e.g., process Y arrives and requires 10 memory units


FIRST-FIT ALGORITHM
-- scan from the "top" of memory until we find
		a free partition that fits process Y

MEMORY (first fit):
-----------------------------------
 AAAAAAAAAAAAAAAAAAAAAAAAAAAAAABBB
 BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB
 BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB
 BCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC
 CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC.
 ....MMMMMMMMMMMMMMMMMMMMMMMMMMMMM
 MMMMMMMMMMMMMMMMMMYYYYYY.........
 .................................
 .................FFFFFFFFFFFFFFFF
 FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF
 FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF
 FGGGGGGGGGGGGGGGGGGGG............
 ................HHHHHHHHHH.......
-----------------------------------

NEXT-FIT ALGORITHM
-- scan from the end of the most recently placed process
	until we find a free partition that fits process Y
	(allowed to wrap around to the top)

	e.g. assume F was the last process placed

MEMORY (next-fit):
-----------------------------------
 AAAAAAAAAAAAAAAAAAAAAAAAAAAAAABBB
 BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB
 BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB
 BCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC
 CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC.
 ....MMMMMMMMMMMMMMMMMMMMMMMMMMMMM
 MMMMMMMMMMMMMMMMMM...............
 .................................
 .................FFFFFFFFFFFFFFFF
 FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF
 FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF
 FGGGGGGGGGGGGGGGGGGGGYYYYYY......
 ................HHHHHHHHHH.......
-----------------------------------

Tiny cost to remember where last process was placed.

BEST-FIT ALGORITHM

-- allocate process Y to the smallest free partition
	that's big enough to fit process Y

MEMORY (best-fit):
-----------------------------------
 AAAAAAAAAAAAAAAAAAAAAAAAAAAAAABBB
 BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB
 BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB
 BCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC
 CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC.
 ....MMMMMMMMMMMMMMMMMMMMMMMMMMMMM
 MMMMMMMMMMMMMMMMMM...............
 .................................
 .................FFFFFFFFFFFFFFFF
 FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF
 FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF
 FGGGGGGGGGGGGGGGGGGGG............
 ................HHHHHHHHHHYYYYYY. <=== place process Y here (best fit), with
-----------------------------------			the hope that if a larger process arrives,
																				we can still place it.

MEMORY (best-fit):
-----------------------------------
 AAAAAAAAAAAAAAAAAAAAAAAAAAAAAABBB
 BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB
 BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB
 BCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC
 CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCZ
 ZZ..MMMMMMMMMMMMMMMMMMMMMMMMMMMMM
 MMMMMMMMMMMMMMMMMMJJJJJJJJJJJJJJ.
 KKKKKKKKKKKKKKK.LLLLLLLLLLLLLL...
 .................FFFFFFFFFFFFFFFF
 FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF
 FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF
 FGGGGGGGGGGGGGGGGGGGGQQQQQQQQQ...
 IIIIIIIIIIIIII..HHHHHHHHHHYYYYYY. 
-----------------------------------
																		
WORST-FIT ALGORITHM
-- allocate process Y to the largest free partition
		that's big enough to fit process Y

MEMORY (worst fit):
-----------------------------------
 AAAAAAAAAAAAAAAAAAAAAAAAAAAAAABBB
 BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB
 BBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBBB
 BCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC
 CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC.
 ....MMMMMMMMMMMMMMMMMMMMMMMMMMMMM
 MMMMMMMMMMMMMMMMMMYYYYYY......... <== place process Y here...?
 .................................
 .................FFFFFFFFFFFFFFFF
 FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF
 FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF
 FGGGGGGGGGGGGGGGGGGGG............
 ................HHHHHHHHHH.......
-----------------------------------

-- does worst-fit give us the benefit of delaying the need for defragmentation?
        ^^^^^^^^^
        any algorithm

============================================================

NON-CONTIGUOUS MEMORY ALLOCATION

-- We avoid the need to defragment memory by using a non-contiguous approach

-- Given process P, we slice up the process into N equally sized PAGES
	(where the last page might not use the entire page of logical memory)

-- Next, we allocate each PAGE to a FRAME of physical memory
		(i.e., frame size == page size)

-- But..... we do need a way to map logical address to a physical address
		-- we implement this mapping using a PAGE TABLE --- overhead... :-(

e.g., a 16-bit memory address with the high-order 4 bits representing the
			page number

	logical address:	0110110011001111 <== binary 16-bit address

									      |
	logical address:	0110|110011001111 <== binary 16-bit address
										 ^  |   ^
										 |      |
										 |      |
									 page     page
									number   offset


								... do the lookup in the page table for 0110 (6),
										which for this process map to (say...) frame 1101 (13)

									frame    frame
									number   offset
										 |      |
										 |      |
										 v  |   v
	physical address: 1101|110011001111 <== binary 16-bit address
												|

At most, how many pages are there per process?

	 4
	2   ===> 16 pages per process (at most)


What is the page size (and therefore frame size) in bytes?

	 12
	2   ===> 4096 bytes

Invariant: page size == frame size

===================================================
[08/08/2019]

PRINCIPLE OF LOCALITY

-- Much more often than not, when we're accessing memory on a
	given page P, the next memory address that we're going to access
	is on the same page, P.

		-- Spatial Locality: Nearby addresses (e.g. instructions in a sequential program)
			 will be used, so still on the same page.

		-- Temporal Locality: Same instruction will be run again soon or
			 same address will be requested again soon (so the same page will be used)

-- Through the use of a Translation Lookaside Buffer (TLB), as long as we
	 achieve a high enough TLB hit ratio, we can significantly reduce the overhead
	 of page table lookups

e.g., each physical memory access requires 100ns (i.e., page table lookup)
		and each TLB memory access requires 20ns (i.e., TLB lookup)

-- Memory access without the use of a TLB:
	 (1) page table memory access (100ns) plus
	 (2) requestd memory access (100ns)
	 ==> each memory access is therefore 200ns

-- Memory access with the use of a TLB:
	 (1) TLB memory access/lookup (20 ns):
			 (2a) TLB cache miss --> page table memory access (100ns)
															 requested memory access (100ns)
															 cache the page-to-frame mapping to the cache
			 (2b) TLB cache hit ---> requested memory access (100 ns)

Effective Memory Access Time (EMAT)
e.g. given the lookup times from above, and a TLB hit rate of 96%...

	EMAT = 0.04 * 220 + 0.96 * 120 = 124 ns
	       ^^^^^^^^^^   ^^^^^^^^^^
	       cache miss   cache hit

TO DO: explore with dfferent hit ratio values: 50%; 75%; 99; 80%; etc.

(Internal fragmentation occurs in the last frame of physical memory 
allocated to a process)

How we determine the page size to use?
-- the smaller the page size, the less internal fragmentation
-- best case, internal fragmentation is zero
-- worst case, internal framgentation is K-1, where K is the page size

-- the smaller the page size, the larger the number of pages required
		and therefore a larger page table is required.
		-- and therefore less advantage gained from the principle of locality
				and using a TLB

VIRTUAL MEMORY

-- Not all page of a process are needed during program execution (at a given time)
-- Only a few pages of a process are needd in physical memory at any given time

-- Virtual address space essentially reside on disk

-- a PAGE FAULT results from a memory access that requires a page that is not 
	 already in physical memory (and therefore needs to be read from disk,
	 i.e., swap the page in from disk)

Remember that the principle of locality is why caching works...

VIRTUAL MEMORY POLICIES

-- The FETCH policy governs when a page should be loaded into physical
	 memory from disk (e.g., demand paging, demand paging with pre-paging
	 that loads some of the adjacent pages into physical memory)

-- The PLACEMENT policy specifies where a page is loaded into physical
	 memory (i.e. the page table)

-- The REPLACEMENT policy determines which existing page of a process
	 (already in physical memory) should be replaced (evicted) when we
	 swap in another page from disk

Page Allocation:
-- In a STATIC ALLOCATION scheme, the number of frames allocated per
	 process is fixed/static (e.g., Process A is allocated 3 frames,
	 Process B is allocated 5 frames, etc.)
-- In a DYNAMIC ALLOCATION scheme, the number of frames allocated per
	 process can vary (based on some criteria for each process)


-- In an EQUAL ALLOCATION scheme, the number of frames allocated is the
	 same for each process (e.g. all processes get 3 frames)
-- In a PROPORTIONAL ALLOCATION scheme, processes are allocated frames
	 in proportion to process size, priority, behavior (page use), etc.

THRASHING
-- A process is in a state of THRASHING if it is spending more time
	 paging/swapping than executing

	 -- as this paging/swapping occurs, the given process is suspended
		  from its execution

Page REPLACEMENT Policy:
--Algorithm for identifying which page (already in physical memory)
	for a given process will be replaced by the newly requested page
	(i.e. the page access that caused the page fault)
-- Goal is to reduce/minimize the number of page faults
-- Goal is also to identify the LOCALITY of the given process at any time

e.g. page reference stream

		1 2 3 2 1 1 3 4 4 2 4 5 7 2 2 8 3 2 2 1 1 .....

		given a 3-frame static allocation scheme for this process

FIFO (first-in first-out)

		1 2 3 2 1 1 3 4 4 2 4 5 7 2 2 8 3 2 2 1 1
	-------------------------------------------
  . 1 1 1 1 1 1 1-4 4 4 4 4 4-2 2 2 2 2 2-1 1
  . . 2 2 2 2 2 2 2 2 2 2-5 5 5 5-8 8 8 8 8 8
  . . . 3 3 3 3 3 3 3 3 3 3-7 7 7 7-3 3 3 3 3
	-------------------------------------------
    p p p         p       p p p   p p     p   <=== 10 page faults

TO DO: repeat this with a 4-frame memory, a 5-frame memory, etc.

LRU (least recently used)

		1 2 3 2 1 1 3 4 4 2 4 5 7 2 2 8 3 2 2 1 1
	-------------------------------------------
  . 1 1 1 1 1 1 1 1 1-2 2 2
  . . 2 2 2 2 2 2-4 4 4 4 4
  . . . 3 3 3 3 3 3 3 3 3-5
	-------------------------------------------
    p p p         p   p   p

TODO: finish this example, repeat with a 4-frame and a 5-frame memory...


LFU (least frequently used)

		1 2 3 2 1 1 3 4 4 2 4 5 7 2 2 8 3 2 2 1 1
	-------------------------------------------
  . 1 1 1 1 1 1 1 
  . . 2 2 2 2 2 2 
  . . . 3 3 3 3 3 
	-------------------------------------------
    p p p         p

					# of memory accesses
	page 1: 3
	page 2: 2
	page 3: 2

	We use a tie-breaker between pages 2 and 3 to figure out which one to evict.
	We could use LRU for our tiebreaker.
	(Could also try things like "lowest page number")

	When is a page is swapped out, its count is reset to zero

	Disadvantages of LFU:
	-- additional overhead
	-- pages that stick around long enough tend to have artificially high
		 frequency/access counts, but new pages always start at 1

TO DO: repeat this with a 4-frame memory, a 5-frame memory, etc.

OPT (optimal) -- i.e. look forward in time

		1 2 3 2 1 1 3 4 4 2 4 5 7 2 2 8 3 2 2 1 1
	-------------------------------------------
  . 1 1 1 1 1 1 1-4 4 4 4-5-7 7 7-8 8 8 8-1 1 
  . . 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
  . . . 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
	-------------------------------------------
    p p p         p       p p     p       p   <=== 8 page faults

TO DO: repeat this with a 4-frame memory, a 5-frame memory, etc.


Working Set
Δ = delta

	e.g. working set delta is 2 (i.e. go back 2 steps)


          v
	1 2 3 2 1 1 3 4 4 2 4 5 7 2 2 8 3 2 2 1 1
      |<->| working set is {1, 2, 3}

            v
	1 2 3 2 1 1 3 4 4 2 4 5 7 2 2 8 3 2 2 1 1
        |<->| working set is {1, 2}

              v
	1 2 3 2 1 1 3 4 4 2 4 5 7 2 2 8 3 2 2 1 1
          |<->| working set is {1, 3}


	e.g. working set delta 5 (i.e. go back 5 steps)

            v
	1 2 3 2 1 1 3 4 4 2 4 5 7 2 2 8 3 2 2 1 1
  |<------->| working set is {1, 2, 3}

              v
	1 2 3 2 1 1 3 4 4 2 4 5 7 2 2 8 3 2 2 1 1
    |<------->| working set is {1, 2, 3}

                v
	1 2 3 2 1 1 3 4 4 2 4 5 7 2 2 8 3 2 2 1 1
      |<------->| working set is {1, 2, 3, 4}

                  v
	1 2 3 2 1 1 3 4 4 2 4 5 7 2 2 8 3 2 2 1 1
        |<------->| working set is {1, 2, 3, 4}


                          v
	1 2 3 2 1 1 3 4 4 2 4 5 7 2 2 8 3 2 2 1 1
                |<------->| working set is {4, 2, 5, 7}


