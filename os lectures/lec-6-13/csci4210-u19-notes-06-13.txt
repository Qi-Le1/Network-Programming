[06/13/2019]

Quiz 2 Graded -- see Submitty for your grades -- average: 14.6/20
-- to request a regrade, please stop by during any office hours
-- for regrade requests, please do these by Fri 6/21 !!!

Homework 2 has been posted -- focus on fork(), pipe(), IPC

Exam 1 is Thursday 6/20 -- attend either lecture time (not both!)
-- see sample exam document for more details....
-- when you arrive (early), please sit with empty seats on either side
    of you and with an empty row in front of you and behind you
-- make sure you are using Ubuntu to study for the exam

/* octuplets-abcd-pipe.c -- based on a true story.... */

/* TO DO: communicate via pipe(s) with the child processes to
           get the modified substrings back to the parent process */


======================================================================

New jobs are admitted into the system
-- long-term or high-level scheduling

Once in the system, processes go through a number of state changes
-- short-term or low-level or CPU scheduling

A process is a "running program" or "program in execution"

Processes have a variety of states:


   RUNNING           READY                 WAITING (on I/O)
    STATE            STATE                  STATE

   +-----+                               +-----------------------+
   |     |     +--------------------+    |                 P2 P8 |
   | CPU | <== | P3 | P6 | P5 | ... |P8<==  I/O Subsystem   P13  |
   | P11 |     +--------------------+    |                       |
   +-----+                               +-----------------------+

 (a CPU burst is a set of assembly instructions that are executed by
   the CPU for a given process)

 (an I/O burst is one or more I/O operations for a given process)


 RUNNING STATE: process is actually using the CPU
                (i.e., executing its instructions)

 READY STATE: process is ready to use the CPU (idle in the ready queue)

 WAITING STATE: process is waiting for I/O operation(s) to complete

==> multiclass-system.png

CPU Scheduling (a.k.a. Short-Term Scheduling)

-- The scheduling system enables one process to use the CPU
    while other processes are waiting in the ready queue to use
     the CPU (or waiting in the I/O subsystem)

-- The goals of CPU scheduling are to make efficient use of the CPU
    and to minimize the turnaround and wait times for each running process

    -- We also want to achieve "fairness" among all processes

-- The task of the CPU scheduler is, when the CPU becomes free,
    to select the next process from the ready queue
     (more specifically, maintain the ready queue in a specific process order)

-- CPU Scheduling Algorithms:

   First Come First Served (FCFS)

   Shortest Job First (SJF)

   Shortest Remaining Time (SRT)

   Priority Scheduling

   Round Robin (RR)

-- Preemption occurs when the currently running process is
    preempted (i.e., "kicked out" or replaced) from using the CPU

    -- might be because of a newly arriving (more important) process

    -- might be because of a timeout (i.e., the RR algorithm)


Processes in a multiprogramming system COMPETE for the CPU
 (but they also often need to COOPERATE with one another via IPC)

Whenever we switch a process out of the CPU and bring the next process
 in to use the CPU, we have a CONTEXT SWITCH

  -- the state of the currently running process is saved in
      a process control block (PCB), which includes registers,
       program counter, page table, memory maps, etc.

  -- the state of the next (or replacement) process is loaded from its PCB

                   OVERHEAD!!!!!!


Other challenges of CPU scheduling include:
-- Processes alternate bursts of CPU time and I/O time;
    how do we best handle the process mix?

   +---------+ blocked +--------------------------+  +--------------+
P1 |CPU burst|---------|       CPU burst          |--|   CPU burst  |-->
   +---------+ on I/O  +--------------------------+  +--------------+

   +---+   blocked on I/O                        +-----+
P2 |CPU|-----------------------------------------| CPU |--------------->
   +---+                                         +-----+

    P1 is a CPU-bound or compute-bound process;
     P2 is an I/O-bound or interactive process

    We can model this as follows:
    -- Consider CPU usage from a probabilistic viewpoint
    -- Suppose processes spend fraction p of their time
        waiting for I/O to complete
    -- Given n processes in memory (i.e., the degree of multiprogramming is n),
        then the probability that all n processes are waiting for I/O is:

                 n
                p

                                     n
    -- CPU utilization is then: 1 - p


-- Scheduling decisions:
-- When does the OS make a scheduling decision?
   -- fork() -- how do we schedule a new child process?
   -- process termination
   -- process blocks on I/O (or enters a waiting/suspended state)
   -- I/O interrupt (the process re-enters the ready queue or maybe
                      causes a preemption)
-- Which process does the OS select next?

-- The above depends on the types of processes

   -- batch: no users are waiting  (lower priority --- non-preemptive)

   -- interactive: users are waiting for a (quick) response; also
       servers serving up file/webpages/etc.  (higher priority --- preemptive)

   -- real-time: preemption not usually necessary because processes
        already are designed to "know" that they need to run quickly


All types of processes:
-- fairness
-- balance

Batch systems:
-- Throughput --- maximize the number of jobs completed per unit time
-- Turnaround time --- minimize time between arrival and completion
-- CPU utilization --- keep CPU as busy as possible

Interactive systems:
-- Response time -- respond to user requests quickly


For each CPU burst per each process:

WAIT TIME: How much time does a process spend in the ready queue
            waiting for time with the CPU?

TURNAROUND TIME: How much time is required for a process to complete
                  its CPU burst, from the time it enters the ready queue
                   through to when it completes its CPU burst


TURNAROUND TIME  =  WAIT TIME  +  CPU BURST TIME

TURNAROUND TIME  =  WAIT TIME  +  CPU BURST TIME  +  OVERHEAD
                                                    (context switches)

First Come First Served (FCFS)

   pid   CPU burst times    (assume that all processes arrive at time 0)
   P1      18 ms
   P2       3 ms
   P3       4 ms

  ready queue is ordered: P1 P2 P3

   context switch       context switches
       v                    v   v    v
       +--------------------+---+----+--------------->
 FCFS: | P1                 |P2 | P3 | ...........
       +--------------------+---+----+--------------->
    t: 0                    18  21   25


    P1 has 0 wait time          P1 has 18 ms turnaround time
    P2 has 18 ms wait time      P2 has 21 ms turnaround time
    P3 has 21 ms wait time      P3 has 25 ms turnaround time

advantages: very simple; easy to implement; very low overhead

disadvantages: processes with larger CPU burst times will likely cause
                long delays for other (shorter) processes


Shortest Job First (SJF)

   pid   CPU burst times    (assume that all processes arrive at time 0)
   P1      18 ms
   P2       3 ms
   P3       4 ms

  ready queue is ordered: P2 P3 P1     (priority queue)

     context switches            context switch
       v   v    v                    v
       +---+----+--------------------+--------------->
  SJF: |P2 | P3 |  P1                | ........
       +---+----+--------------------+--------------->
    t: 0   3    7                    25

    P1 has 7 ms wait time       P1 has 25 ms turnaround time
    P2 has 0 wait time          P2 has 3 ms turnaround time
    P3 has 3 ms wait time       P3 has 7 ms turnaround time

advantages: lower average wait/turnaround times (versus FCFS)
            good low turnaround times for interactive or I/O-bound processes

disadvantages: processes with larger CPU burst times might end up
                 facing INDEFINITE BLOCKING or STARVATION

               higher overhead versus FCFS due to the priority queue

               irl we have no way of knowing ahead of time exactly what
                the CPU burst times will be for each process.....
                  .......but we can predict the CPU burst times


Both FCFS and SJF are non-preemptive algorithms
-- once a process starts using the CPU for its CPU burst,
    it will continue uninterrupted until the burst is complete

-- what if we added preemption to SJF?
   -- i.e., when new process B arrives, it can potentially preempt
       (replace) the currently running process A if B's CPU burst time
        is less than the remaining burst time for process A

Shortest Remaining Time (SRT)
-- SJF with preemption

   pid   CPU burst times      arrival times
   P1      18 ms                   0 ms
   P2       3 ms                   2 ms
   P3       4 ms                   3 ms
   P4       3 ms                   5 ms

  TO DO: draw the diagram for these processes and calculate
          the turnaround/wait times for each


